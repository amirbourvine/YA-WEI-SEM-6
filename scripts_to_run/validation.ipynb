{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: optuna in /home/amirbourvine/.local/lib/python3.10/site-packages (3.6.1)\n",
      "Requirement already satisfied: tqdm in /home/amirbourvine/.local/lib/python3.10/site-packages (from optuna) (4.66.4)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /home/amirbourvine/.local/lib/python3.10/site-packages (from optuna) (2.0.31)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.24.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/amirbourvine/.local/lib/python3.10/site-packages (from optuna) (24.0)\n",
      "Requirement already satisfied: colorlog in /home/amirbourvine/.local/lib/python3.10/site-packages (from optuna) (6.8.2)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /home/amirbourvine/.local/lib/python3.10/site-packages (from optuna) (1.13.1)\n",
      "Requirement already satisfied: PyYAML in /usr/lib/python3/dist-packages (from optuna) (5.4.1)\n",
      "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (1.2.4)\n",
      "Requirement already satisfied: typing-extensions>=4 in /home/amirbourvine/.local/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (4.12.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/lib/python3/dist-packages (from sqlalchemy>=1.3.0->optuna) (1.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../utils/')\n",
    "sys.path.append('../paviaUTools/')\n",
    "# sys.path.insert(1, '../utils')\n",
    "# sys.path.insert(2, '../paviaUTools')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from datasetLoader import datasetLoader\n",
    "import os\n",
    "import numpy as np\n",
    "from whole_pipeline import whole_pipeline_all, whole_pipeline_divided, whole_pipeline_divided_parallel\n",
    "import torch\n",
    "from plots import *\n",
    "from weights_anal import *\n",
    "from MetaLearner import HDDOnBands\n",
    "import consts\n",
    "\n",
    "import gc\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "parent_dir = os.path.join(os.getcwd(),\"..\")\n",
    "csv_path = os.path.join(parent_dir, 'datasets', 'paviaU.csv')\n",
    "gt_path = os.path.join(parent_dir, 'datasets', 'paviaU_gt.csv')\n",
    "# csv_path = os.path.join(parent_dir, 'datasets', 'pavia.csv')\n",
    "# gt_path = os.path.join(parent_dir, 'datasets', 'pavia_gt.csv')\n",
    "\n",
    "dsl = datasetLoader(csv_path, gt_path)\n",
    "\n",
    "df = dsl.read_dataset(gt=False)\n",
    "X = np.array(df)\n",
    "X = X.reshape((610,340, 103))\n",
    "# X = X.reshape((1096, 715, 102))\n",
    "\n",
    "df = dsl.read_dataset(gt=True)\n",
    "y = np.array(df)\n",
    "\n",
    "X = torch.from_numpy(X)\n",
    "y = torch.from_numpy(y)\n",
    "\n",
    "X = X.to(device)\n",
    "y = y.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor = 7\n",
    "reps = 5\n",
    "min_hyperparam = 0.1\n",
    "max_hyperparam = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "def evaluate(c):\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    consts.CONST_C = c\n",
    "\n",
    "    avg_acc_test = 0.0\n",
    "    for _ in range(reps):\n",
    "        train_acc,test_acc, test_preds,test_gt = whole_pipeline_all(X,y, factor, factor, is_normalize_each_band=True, method_label_patch='most_common')\n",
    "        avg_acc_test += test_acc/reps\n",
    "\n",
    "    score = avg_acc_test\n",
    "    return score\n",
    "\n",
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    # Suggest a value for the hyperparameter within a given range\n",
    "    hyperparameter = trial.suggest_float('c', min_hyperparam, max_hyperparam)\n",
    "    \n",
    "    # Evaluate the hyperparameter\n",
    "    score = evaluate(hyperparameter)\n",
    "    \n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-19 21:20:45,968] A new study created in memory with name: no-name-8eaf5ff0-4953-410f-a690-ef5f985c5f6b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XXXXXXX IN METHOD XXXXXXXXX\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-06-19 21:21:00,435] Trial 0 failed with parameters: {'c': 22.212299535386034} because of the following error: TypeError('zeros() received an invalid combination of arguments - got (tuple, device=torch.device, dtype=torch.dtype), but expected one of:\\n * (tuple of ints size, *, tuple of names names, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\\n * (tuple of ints size, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\\n').\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amirbourvine/.local/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_442427/548659408.py\", line 23, in objective\n",
      "    score = evaluate(hyperparameter)\n",
      "  File \"/tmp/ipykernel_442427/548659408.py\", line 11, in evaluate\n",
      "    train_acc,test_acc, test_preds,test_gt = whole_pipeline_all(X,y, factor, factor, is_normalize_each_band=True, method_label_patch='most_common')\n",
      "  File \"/home/amirbourvine/Desktop/YA-WEI-SEM-6/scripts_to_run/../paviaUTools/whole_pipeline.py\", line 20, in whole_pipeline_all\n",
      "    d_HDD, labels_padded, num_patches_in_row,y_patches = my_HDD_HDE.calc_hdd()\n",
      "  File \"/home/amirbourvine/Desktop/YA-WEI-SEM-6/scripts_to_run/../utils/HDD_HDE.py\", line 273, in calc_hdd\n",
      "    hdd_mat = HDD_HDE.run_method(distances)\n",
      "  File \"/home/amirbourvine/Desktop/YA-WEI-SEM-6/scripts_to_run/../utils/HDD_HDE.py\", line 288, in run_method\n",
      "    HDE = HDD_HDE.hde(distances)\n",
      "  File \"/home/amirbourvine/Desktop/YA-WEI-SEM-6/scripts_to_run/../utils/HDD_HDE.py\", line 113, in hde\n",
      "    X = torch.zeros((consts.CONST_K + 1, shortest_paths_mat.shape[0], shortest_paths_mat.shape[1] + 1), dtype= consts.dist_dtype, device=device)\n",
      "TypeError: zeros() received an invalid combination of arguments - got (tuple, device=torch.device, dtype=torch.dtype), but expected one of:\n",
      " * (tuple of ints size, *, tuple of names names, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n",
      " * (tuple of ints size, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n",
      "\n",
      "[W 2024-06-19 21:21:00,436] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "zeros() received an invalid combination of arguments - got (tuple, device=torch.device, dtype=torch.dtype), but expected one of:\n * (tuple of ints size, *, tuple of names names, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of ints size, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmaximize\u001b[39m\u001b[39m'\u001b[39m)  \u001b[39m# or 'maximize' depending on your evaluation function\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m# Start the optimization\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m study\u001b[39m.\u001b[39;49moptimize(objective, n_trials\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n\u001b[1;32m      7\u001b[0m \u001b[39m# Print the best hyperparameter and its corresponding score\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBest Hyperparameter: \u001b[39m\u001b[39m\"\u001b[39m, study\u001b[39m.\u001b[39mbest_params[\u001b[39m'\u001b[39m\u001b[39mc\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m     \u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     _optimize(\n\u001b[1;32m    452\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    453\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[1;32m    454\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[1;32m    455\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    456\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    457\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[1;32m    458\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    459\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[1;32m    460\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[1;32m    461\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/optuna/study/_optimize.py:62\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 62\u001b[0m         _optimize_sequential(\n\u001b[1;32m     63\u001b[0m             study,\n\u001b[1;32m     64\u001b[0m             func,\n\u001b[1;32m     65\u001b[0m             n_trials,\n\u001b[1;32m     66\u001b[0m             timeout,\n\u001b[1;32m     67\u001b[0m             catch,\n\u001b[1;32m     68\u001b[0m             callbacks,\n\u001b[1;32m     69\u001b[0m             gc_after_trial,\n\u001b[1;32m     70\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     71\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     72\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[1;32m     73\u001b[0m         )\n\u001b[1;32m     74\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     75\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/optuna/study/_optimize.py:159\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 159\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    160\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    161\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/optuna/study/_optimize.py:247\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    242\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    243\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[1;32m    244\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    245\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    246\u001b[0m ):\n\u001b[0;32m--> 247\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[1;32m    248\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/optuna/study/_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[1;32m    195\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[1;32m    197\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    198\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[9], line 23\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     20\u001b[0m hyperparameter \u001b[39m=\u001b[39m trial\u001b[39m.\u001b[39msuggest_float(\u001b[39m'\u001b[39m\u001b[39mc\u001b[39m\u001b[39m'\u001b[39m, min_hyperparam, max_hyperparam)\n\u001b[1;32m     22\u001b[0m \u001b[39m# Evaluate the hyperparameter\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m score \u001b[39m=\u001b[39m evaluate(hyperparameter)\n\u001b[1;32m     25\u001b[0m \u001b[39mreturn\u001b[39;00m score\n",
      "Cell \u001b[0;32mIn[9], line 11\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(c)\u001b[0m\n\u001b[1;32m      9\u001b[0m avg_acc_test \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(reps):\n\u001b[0;32m---> 11\u001b[0m     train_acc,test_acc, test_preds,test_gt \u001b[39m=\u001b[39m whole_pipeline_all(X,y, factor, factor, is_normalize_each_band\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, method_label_patch\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmost_common\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     12\u001b[0m     avg_acc_test \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m test_acc\u001b[39m/\u001b[39mreps\n\u001b[1;32m     14\u001b[0m score \u001b[39m=\u001b[39m avg_acc_test\n",
      "File \u001b[0;32m~/Desktop/YA-WEI-SEM-6/scripts_to_run/../paviaUTools/whole_pipeline.py:20\u001b[0m, in \u001b[0;36mwhole_pipeline_all\u001b[0;34m(X, y, rows_factor, cols_factor, is_normalize_each_band, method_label_patch, random_seed, method_type, distances_bands, precomputed_distances)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mXXXXXXX IN METHOD XXXXXXXXX\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m st \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m---> 20\u001b[0m d_HDD, labels_padded, num_patches_in_row,y_patches \u001b[39m=\u001b[39m my_HDD_HDE\u001b[39m.\u001b[39;49mcalc_hdd()\n\u001b[1;32m     22\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mWHOLE METHOD TIME: \u001b[39m\u001b[39m\"\u001b[39m, time\u001b[39m.\u001b[39mtime()\u001b[39m-\u001b[39mst, flush\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     23\u001b[0m st \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n",
      "File \u001b[0;32m~/Desktop/YA-WEI-SEM-6/scripts_to_run/../utils/HDD_HDE.py:273\u001b[0m, in \u001b[0;36mHDD_HDE.calc_hdd\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcalc_hdd\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    271\u001b[0m     distances,y_patches,num_patches_in_row, labels_padded \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare()\n\u001b[0;32m--> 273\u001b[0m     hdd_mat \u001b[39m=\u001b[39m HDD_HDE\u001b[39m.\u001b[39;49mrun_method(distances)\n\u001b[1;32m    275\u001b[0m     \u001b[39mreturn\u001b[39;00m hdd_mat, labels_padded, num_patches_in_row,y_patches\n",
      "File \u001b[0;32m~/Desktop/YA-WEI-SEM-6/scripts_to_run/../utils/HDD_HDE.py:288\u001b[0m, in \u001b[0;36mHDD_HDE.run_method\u001b[0;34m(distances)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_method\u001b[39m(distances):\n\u001b[1;32m    287\u001b[0m     P \u001b[39m=\u001b[39m HDD_HDE\u001b[39m.\u001b[39mcalc_P(distances, apply_2_norm\u001b[39m=\u001b[39mconsts\u001b[39m.\u001b[39mAPPLY_2_NORM)\n\u001b[0;32m--> 288\u001b[0m     HDE \u001b[39m=\u001b[39m HDD_HDE\u001b[39m.\u001b[39;49mhde(distances)\n\u001b[1;32m    289\u001b[0m     \u001b[39mdel\u001b[39;00m distances\n\u001b[1;32m    290\u001b[0m     torch\u001b[39m.\u001b[39mabs(HDE, out\u001b[39m=\u001b[39mHDE)\n",
      "File \u001b[0;32m~/Desktop/YA-WEI-SEM-6/scripts_to_run/../utils/HDD_HDE.py:113\u001b[0m, in \u001b[0;36mHDD_HDE.hde\u001b[0;34m(shortest_paths_mat)\u001b[0m\n\u001b[1;32m    110\u001b[0m S_keep \u001b[39m=\u001b[39m S_keep\u001b[39m.\u001b[39mdouble()\n\u001b[1;32m    111\u001b[0m Vt \u001b[39m=\u001b[39m Vt\u001b[39m.\u001b[39mdouble()\n\u001b[0;32m--> 113\u001b[0m X \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mzeros((consts\u001b[39m.\u001b[39;49mCONST_K \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m, shortest_paths_mat\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m], shortest_paths_mat\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m] \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), dtype\u001b[39m=\u001b[39;49m consts\u001b[39m.\u001b[39;49mdist_dtype, device\u001b[39m=\u001b[39;49mdevice)\n\u001b[1;32m    114\u001b[0m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m (\u001b[39m0\u001b[39m, consts\u001b[39m.\u001b[39mCONST_K \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[1;32m    115\u001b[0m     S \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfloat_power(S_keep, \u001b[39m2\u001b[39m \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m (\u001b[39m-\u001b[39mk))\n",
      "\u001b[0;31mTypeError\u001b[0m: zeros() received an invalid combination of arguments - got (tuple, device=torch.device, dtype=torch.dtype), but expected one of:\n * (tuple of ints size, *, tuple of names names, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of ints size, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n"
     ]
    }
   ],
   "source": [
    "# Create a study object and specify the direction of optimization\n",
    "study = optuna.create_study(direction='maximize')  # or 'maximize' depending on your evaluation function\n",
    "\n",
    "# Start the optimization\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "# Print the best hyperparameter and its corresponding score\n",
    "print(\"Best Hyperparameter: \", study.best_params['c'])\n",
    "print(\"Best Score: \", study.best_value)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
