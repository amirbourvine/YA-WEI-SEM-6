{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.any(M==torch.nan) ?  tensor(False, device='cuda:0')\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "METHOD:  3\n",
      "0  /  264\n",
      "1  /  264\n",
      "2  /  264\n",
      "3  /  264\n",
      "4  /  264\n",
      "5  /  264\n",
      "6  /  264\n",
      "7  /  264\n",
      "8  /  264\n",
      "9  /  264\n",
      "10  /  264\n",
      "11  /  264\n",
      "12  /  264\n",
      "13  /  264\n",
      "14  /  264\n",
      "15  /  264\n",
      "16  /  264\n",
      "17  /  264\n",
      "18  /  264\n",
      "19  /  264\n",
      "20  /  264\n",
      "21  /  264\n",
      "22  /  264\n",
      "23  /  264\n",
      "24  /  264\n",
      "25  /  264\n",
      "26  /  264\n",
      "27  /  264\n",
      "28  /  264\n",
      "29  /  264\n",
      "30  /  264\n",
      "31  /  264\n",
      "32  /  264\n",
      "33  /  264\n",
      "34  /  264\n",
      "35  /  264\n",
      "36  /  264\n",
      "37  /  264\n",
      "38  /  264\n",
      "39  /  264\n",
      "40  /  264\n",
      "41  /  264\n",
      "42  /  264\n",
      "43  /  264\n",
      "44  /  264\n",
      "45  /  264\n",
      "46  /  264\n",
      "47  /  264\n",
      "48  /  264\n",
      "49  /  264\n",
      "50  /  264\n",
      "51  /  264\n",
      "52  /  264\n",
      "53  /  264\n",
      "54  /  264\n",
      "55  /  264\n",
      "56  /  264\n",
      "57  /  264\n",
      "58  /  264\n",
      "59  /  264\n",
      "60  /  264\n",
      "61  /  264\n",
      "62  /  264\n",
      "63  /  264\n",
      "64  /  264\n",
      "65  /  264\n",
      "66  /  264\n",
      "67  /  264\n",
      "68  /  264\n",
      "69  /  264\n",
      "70  /  264\n",
      "71  /  264\n",
      "72  /  264\n",
      "73  /  264\n",
      "74  /  264\n",
      "75  /  264\n",
      "76  /  264\n",
      "77  /  264\n",
      "78  /  264\n",
      "79  /  264\n",
      "80  /  264\n",
      "81  /  264\n",
      "82  /  264\n",
      "83  /  264\n",
      "84  /  264\n",
      "85  /  264\n",
      "86  /  264\n",
      "87  /  264\n",
      "88  /  264\n",
      "89  /  264\n",
      "90  /  264\n",
      "91  /  264\n",
      "92  /  264\n",
      "93  /  264\n",
      "94  /  264\n",
      "95  /  264\n",
      "96  /  264\n",
      "97  /  264\n",
      "98  /  264\n",
      "99  /  264\n",
      "100  /  264\n",
      "101  /  264\n",
      "102  /  264\n",
      "103  /  264\n",
      "104  /  264\n",
      "105  /  264\n",
      "106  /  264\n",
      "107  /  264\n",
      "108  /  264\n",
      "109  /  264\n",
      "110  /  264\n",
      "111  /  264\n",
      "112  /  264\n",
      "113  /  264\n",
      "114  /  264\n",
      "115  /  264\n",
      "116  /  264\n",
      "117  /  264\n",
      "118  /  264\n",
      "119  /  264\n",
      "120  /  264\n",
      "121  /  264\n",
      "122  /  264\n",
      "123  /  264\n",
      "124  /  264\n",
      "125  /  264\n",
      "126  /  264\n",
      "127  /  264\n",
      "128  /  264\n",
      "129  /  264\n",
      "130  /  264\n",
      "131  /  264\n",
      "132  /  264\n",
      "133  /  264\n",
      "134  /  264\n",
      "135  /  264\n",
      "136  /  264\n",
      "137  /  264\n",
      "138  /  264\n",
      "139  /  264\n",
      "140  /  264\n",
      "141  /  264\n",
      "142  /  264\n",
      "143  /  264\n",
      "144  /  264\n",
      "145  /  264\n",
      "146  /  264\n",
      "147  /  264\n",
      "148  /  264\n",
      "149  /  264\n",
      "150  /  264\n",
      "151  /  264\n",
      "152  /  264\n",
      "153  /  264\n",
      "154  /  264\n",
      "155  /  264\n",
      "156  /  264\n",
      "157  /  264\n",
      "158  /  264\n",
      "159  /  264\n",
      "160  /  264\n",
      "161  /  264\n",
      "162  /  264\n",
      "163  /  264\n",
      "164  /  264\n",
      "165  /  264\n",
      "166  /  264\n",
      "167  /  264\n",
      "168  /  264\n",
      "169  /  264\n",
      "170  /  264\n",
      "171  /  264\n",
      "172  /  264\n",
      "173  /  264\n",
      "174  /  264\n",
      "175  /  264\n",
      "176  /  264\n",
      "177  /  264\n",
      "178  /  264\n",
      "179  /  264\n",
      "180  /  264\n",
      "181  /  264\n",
      "182  /  264\n",
      "183  /  264\n",
      "184  /  264\n",
      "185  /  264\n",
      "186  /  264\n",
      "187  /  264\n",
      "188  /  264\n",
      "189  /  264\n",
      "190  /  264\n",
      "191  /  264\n",
      "192  /  264\n",
      "193  /  264\n",
      "194  /  264\n",
      "195  /  264\n",
      "196  /  264\n",
      "197  /  264\n",
      "198  /  264\n",
      "199  /  264\n",
      "200  /  264\n",
      "201  /  264\n",
      "202  /  264\n",
      "203  /  264\n",
      "204  /  264\n",
      "205  /  264\n",
      "206  /  264\n",
      "207  /  264\n",
      "208  /  264\n",
      "209  /  264\n",
      "210  /  264\n",
      "211  /  264\n",
      "212  /  264\n",
      "213  /  264\n",
      "214  /  264\n",
      "215  /  264\n",
      "216  /  264\n",
      "217  /  264\n",
      "218  /  264\n",
      "219  /  264\n",
      "220  /  264\n",
      "221  /  264\n",
      "222  /  264\n",
      "223  /  264\n",
      "224  /  264\n",
      "225  /  264\n",
      "226  /  264\n",
      "227  /  264\n",
      "228  /  264\n",
      "229  /  264\n",
      "230  /  264\n",
      "231  /  264\n",
      "232  /  264\n",
      "233  /  264\n",
      "234  /  264\n",
      "235  /  264\n",
      "236  /  264\n",
      "237  /  264\n",
      "238  /  264\n",
      "239  /  264\n",
      "240  /  264\n",
      "241  /  264\n",
      "242  /  264\n",
      "243  /  264\n",
      "244  /  264\n",
      "245  /  264\n",
      "246  /  264\n",
      "247  /  264\n",
      "248  /  264\n",
      "249  /  264\n",
      "250  /  264\n",
      "251  /  264\n",
      "252  /  264\n",
      "253  /  264\n",
      "254  /  264\n",
      "255  /  264\n",
      "256  /  264\n",
      "257  /  264\n",
      "258  /  264\n",
      "259  /  264\n",
      "260  /  264\n",
      "261  /  264\n",
      "262  /  264\n",
      "263  /  264\n",
      "XXXXXXX IN METHOD XXXXXXXXX\n",
      "torch.any(M==torch.nan) ?  tensor(False, device='cuda:0')\n",
      "WHOLE METHOD TIME:  0.23700952529907227\n",
      "XXXXXXX IN CLASSIFICATION XXXXXXXXX\n",
      "total classified:  34113\n",
      "total classified:  8662\n",
      "Train Accuracy:  0.8823322487028405\n",
      "Test Accuracy:  0.7876933733548834\n",
      "iteration  0  DONE\n",
      "XXXXXXX IN METHOD XXXXXXXXX\n",
      "torch.any(M==torch.nan) ?  tensor(False, device='cuda:0')\n",
      "WHOLE METHOD TIME:  0.22446346282958984\n",
      "XXXXXXX IN CLASSIFICATION XXXXXXXXX\n",
      "total classified:  33956\n",
      "total classified:  8819\n",
      "Train Accuracy:  0.8901225114854517\n",
      "Test Accuracy:  0.4954076425898628\n",
      "iteration  1  DONE\n",
      "XXXXXXX IN METHOD XXXXXXXXX\n",
      "torch.any(M==torch.nan) ?  tensor(False, device='cuda:0')\n",
      "WHOLE METHOD TIME:  0.22430086135864258\n",
      "XXXXXXX IN CLASSIFICATION XXXXXXXXX\n",
      "total classified:  34295\n",
      "total classified:  8480\n",
      "Train Accuracy:  0.8841813675462895\n",
      "Test Accuracy:  0.49292452830188677\n",
      "iteration  2  DONE\n",
      "XXXXXXX IN METHOD XXXXXXXXX\n",
      "torch.any(M==torch.nan) ?  tensor(False, device='cuda:0')\n",
      "WHOLE METHOD TIME:  0.2237088680267334\n",
      "XXXXXXX IN CLASSIFICATION XXXXXXXXX\n",
      "total classified:  33258\n",
      "total classified:  9517\n",
      "Train Accuracy:  0.8752179926634194\n",
      "Test Accuracy:  0.7096774193548387\n",
      "iteration  3  DONE\n",
      "XXXXXXX IN METHOD XXXXXXXXX\n",
      "torch.any(M==torch.nan) ?  tensor(False, device='cuda:0')\n",
      "WHOLE METHOD TIME:  0.22381305694580078\n",
      "XXXXXXX IN CLASSIFICATION XXXXXXXXX\n",
      "total classified:  34356\n",
      "total classified:  8419\n",
      "Train Accuracy:  0.8840086156712074\n",
      "Test Accuracy:  0.3737973631072574\n",
      "iteration  4  DONE\n",
      "factor:  29\n",
      "avg_acc_train:  0.8831725472138418\n",
      "avg_acc_test:  0.5719000653417458\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../utils/')\n",
    "sys.path.append('../paviaUTools/')\n",
    "# sys.path.insert(1, '../utils')\n",
    "# sys.path.insert(2, '../paviaUTools')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from datasetLoader import datasetLoader\n",
    "import os\n",
    "import numpy as np\n",
    "from whole_pipeline import whole_pipeline_all, whole_pipeline_divided, whole_pipeline_divided_parallel\n",
    "import torch\n",
    "from plots import *\n",
    "from weights_anal import *\n",
    "from MetaLearner import HDDOnBands\n",
    "from consts import *\n",
    "from HDD_HDE import HDD_HDE\n",
    "import DistancesHandler\n",
    "\n",
    "import gc\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "parent_dir = os.path.join(os.getcwd(),\"..\")\n",
    "csv_path = os.path.join(parent_dir, 'datasets', 'paviaU.csv')\n",
    "gt_path = os.path.join(parent_dir, 'datasets', 'paviaU_gt.csv')\n",
    "# csv_path = os.path.join(parent_dir, 'datasets', 'pavia.csv')\n",
    "# gt_path = os.path.join(parent_dir, 'datasets', 'pavia_gt.csv')\n",
    "\n",
    "dsl = datasetLoader(csv_path, gt_path)\n",
    "\n",
    "df = dsl.read_dataset(gt=False)\n",
    "X = np.array(df)\n",
    "X = X.reshape((610,340, 103))\n",
    "# X = X.reshape((1096, 715, 102))\n",
    "\n",
    "df = dsl.read_dataset(gt=True)\n",
    "y = np.array(df)\n",
    "\n",
    "X = torch.from_numpy(X)\n",
    "y = torch.from_numpy(y)\n",
    "\n",
    "X = X.to(device)\n",
    "y = y.to(device)\n",
    "\n",
    "reps = 5\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "random_seeds = [-923723872,\n",
    "883017324,\n",
    "531811554,\n",
    "2047094521,\n",
    "1767143556,\n",
    "112000582,\n",
    "-1699501351,\n",
    "-2096286485,\n",
    "-1079138285,\n",
    "-424805109]\n",
    "\n",
    "distances_bands = HDDOnBands.run(X)\n",
    "distances_bands = distances_bands.to(device)\n",
    "\n",
    "is_normalize_each_band = True\n",
    "method_label_patch='most_common'\n",
    "\n",
    "\n",
    "for method in [WASSERSTEIN]:\n",
    "    print(\"@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\")\n",
    "    print(\"METHOD: \", method)\n",
    "\n",
    "    for factor in [29]:\n",
    "        if is_normalize_each_band:\n",
    "            X_tmp = HDD_HDE.normalize_each_band(X)\n",
    "        else:\n",
    "            X_tmp = X\n",
    "        X_patches, _, _= HDD_HDE.patch_data_class(X_tmp, factor, factor, y, method_label_patch)\n",
    "        distance_handler = DistancesHandler.DistanceHandler(WASSERSTEIN,distances_bands)\n",
    "        precomputed_distances = distance_handler.calc_distances(X_patches)\n",
    "\n",
    "\n",
    "\n",
    "        avg_acc_train = 0.0\n",
    "        avg_acc_test = 0.0\n",
    "        for i in range(reps):\n",
    "            train_acc,test_acc, test_preds,test_gt = whole_pipeline_all(X,y, factor, factor, is_normalize_each_band=is_normalize_each_band, method_label_patch=method_label_patch, random_seed=random_seeds[i], method_type = method, distances_bands=distances_bands, precomputed_distances = precomputed_distances)\n",
    "            avg_acc_train += train_acc/reps\n",
    "            avg_acc_test += test_acc/reps\n",
    "\n",
    "            print(\"iteration \", i, \" DONE\")\n",
    "\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "        print(\"factor: \", factor)\n",
    "        print(\"avg_acc_train: \", avg_acc_train)\n",
    "        print(\"avg_acc_test: \", avg_acc_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
